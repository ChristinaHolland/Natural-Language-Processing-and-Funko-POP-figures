{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### project3_6_randomforest_supportvector.ipynb,\n",
    "\n",
    "wherein I try a couple more models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import my now pretty long list of libraries:\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize, RegexpTokenizer\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load in my data and other dataframes as before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>date</th>\n",
       "      <th>types</th>\n",
       "      <th>char_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I think it's the end of the first episode rath...</td>\n",
       "      <td>1615999558</td>\n",
       "      <td>fantasy</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I think you mean the prologue of the Wheel of ...</td>\n",
       "      <td>1615999475</td>\n",
       "      <td>fantasy</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Not properly \"Fantasy\", but \"Horus Rising\" ope...</td>\n",
       "      <td>1615999395</td>\n",
       "      <td>fantasy</td>\n",
       "      <td>218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Love that trilogy. Bit slow to get started (af...</td>\n",
       "      <td>1615999383</td>\n",
       "      <td>fantasy</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&amp;gt;At this point I think Sanderson being the ...</td>\n",
       "      <td>1615999332</td>\n",
       "      <td>fantasy</td>\n",
       "      <td>566</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             comment        date    types  \\\n",
       "0  I think it's the end of the first episode rath...  1615999558  fantasy   \n",
       "1  I think you mean the prologue of the Wheel of ...  1615999475  fantasy   \n",
       "2  Not properly \"Fantasy\", but \"Horus Rising\" ope...  1615999395  fantasy   \n",
       "3  Love that trilogy. Bit slow to get started (af...  1615999383  fantasy   \n",
       "4  &gt;At this point I think Sanderson being the ...  1615999332  fantasy   \n",
       "\n",
       "   char_length  \n",
       "0           76  \n",
       "1           87  \n",
       "2          218  \n",
       "3           85  \n",
       "4          566  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./data/redditcomments.csv')\n",
    "df.drop(columns='Unnamed: 0',inplace=True)\n",
    "df.dropna(inplace=True)\n",
    "df['char_length'] = [len(comment) for comment in list(df['comment'])]\n",
    "df = df[(df['char_length']>=10) & (df['char_length']<1000)]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 18746 entries, 0 to 19999\n",
      "Data columns (total 4 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   comment      18746 non-null  object\n",
      " 1   date         18746 non-null  int64 \n",
      " 2   types        18746 non-null  object\n",
      " 3   char_length  18746 non-null  int64 \n",
      "dtypes: int64(2), object(2)\n",
      "memory usage: 732.3+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments = list(df['comment'])\n",
    "df['flagged'] = [1 if ('removed' in comment.split(' ')) else 0 for comment in comments]\n",
    "df = df[df['flagged']==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['thick',\n",
       " 'beyond',\n",
       " 'six',\n",
       " 'hereafter',\n",
       " 'both',\n",
       " 'her',\n",
       " 'am',\n",
       " 'forty',\n",
       " 'very',\n",
       " 'its',\n",
       " 'above',\n",
       " 'ours',\n",
       " 'who',\n",
       " 'someone',\n",
       " 'might',\n",
       " 'whenever',\n",
       " 'per',\n",
       " 'un',\n",
       " 'may',\n",
       " 'cannot',\n",
       " 'formerly',\n",
       " 'before',\n",
       " 'up',\n",
       " 'of',\n",
       " 'amongst',\n",
       " 'couldnt',\n",
       " 'more',\n",
       " 'four',\n",
       " 'it',\n",
       " 'thereupon',\n",
       " 'there',\n",
       " 'again',\n",
       " 'him',\n",
       " 'beside',\n",
       " 'they',\n",
       " 'less',\n",
       " 'us',\n",
       " 'hasnt',\n",
       " 'in',\n",
       " 'while',\n",
       " 'one',\n",
       " 'seeming',\n",
       " 'had',\n",
       " 'several',\n",
       " 'thereafter',\n",
       " 'since',\n",
       " 'ten',\n",
       " 'for',\n",
       " 'too',\n",
       " 'been',\n",
       " 'de',\n",
       " 'etc',\n",
       " 'herself',\n",
       " 'wherein',\n",
       " 'herein',\n",
       " 'during',\n",
       " 'such',\n",
       " 'noone',\n",
       " 'yours',\n",
       " 'serious',\n",
       " 'whether',\n",
       " 'enough',\n",
       " 'whoever',\n",
       " 'cant',\n",
       " 'must',\n",
       " 'eg',\n",
       " 'otherwise',\n",
       " 'itself',\n",
       " 'get',\n",
       " 'them',\n",
       " 'why',\n",
       " 'few',\n",
       " 'nobody',\n",
       " 'rather',\n",
       " 'between',\n",
       " 'ourselves',\n",
       " 'fill',\n",
       " 'below',\n",
       " 'are',\n",
       " 'indeed',\n",
       " 'mine',\n",
       " 'still',\n",
       " 'perhaps',\n",
       " 'thence',\n",
       " 'most',\n",
       " 'others',\n",
       " 'no',\n",
       " 'go',\n",
       " 'then',\n",
       " 'inc',\n",
       " 'have',\n",
       " 'hers',\n",
       " 'twenty',\n",
       " 'this',\n",
       " 'full',\n",
       " 'me',\n",
       " 'either',\n",
       " 'side',\n",
       " 'onto',\n",
       " 'five',\n",
       " 'latterly',\n",
       " 'con',\n",
       " 'except',\n",
       " 'can',\n",
       " 'off',\n",
       " 'against',\n",
       " 'any',\n",
       " 'through',\n",
       " 'everything',\n",
       " 'give',\n",
       " 'mostly',\n",
       " 'his',\n",
       " 'many',\n",
       " 'where',\n",
       " 'please',\n",
       " 'whatever',\n",
       " 'yet',\n",
       " 'an',\n",
       " 'sincere',\n",
       " 'along',\n",
       " 'became',\n",
       " 'everywhere',\n",
       " 'is',\n",
       " 'into',\n",
       " 'eight',\n",
       " 'co',\n",
       " 'he',\n",
       " 'without',\n",
       " 'thus',\n",
       " 'latter',\n",
       " 'if',\n",
       " 'due',\n",
       " 'put',\n",
       " 'our',\n",
       " 'anyway',\n",
       " 'even',\n",
       " 'fifty',\n",
       " 'three',\n",
       " 'see',\n",
       " 'interest',\n",
       " 'nor',\n",
       " 'although',\n",
       " 'anyhow',\n",
       " 'other',\n",
       " 'sixty',\n",
       " 'himself',\n",
       " 'which',\n",
       " 'whereby',\n",
       " 'none',\n",
       " 'my',\n",
       " 'become',\n",
       " 'elsewhere',\n",
       " 'wherever',\n",
       " 'first',\n",
       " 'about',\n",
       " 'over',\n",
       " 'bottom',\n",
       " 'ltd',\n",
       " 'ever',\n",
       " 'your',\n",
       " 'fire',\n",
       " 'amount',\n",
       " 'how',\n",
       " 'bill',\n",
       " 'ie',\n",
       " 'here',\n",
       " 'least',\n",
       " 'with',\n",
       " 'never',\n",
       " 'part',\n",
       " 'should',\n",
       " 'or',\n",
       " 'do',\n",
       " 'whereafter',\n",
       " 'being',\n",
       " 'out',\n",
       " 'on',\n",
       " 'much',\n",
       " 'whence',\n",
       " 'show',\n",
       " 'towards',\n",
       " 'done',\n",
       " 'describe',\n",
       " 'would',\n",
       " 'not',\n",
       " 'somewhere',\n",
       " 're',\n",
       " 'front',\n",
       " 'to',\n",
       " 'everyone',\n",
       " 'i',\n",
       " 'via',\n",
       " 'therefore',\n",
       " 'because',\n",
       " 'every',\n",
       " 'nowhere',\n",
       " 'myself',\n",
       " 'move',\n",
       " 'be',\n",
       " 'anyone',\n",
       " 'whose',\n",
       " 'already',\n",
       " 'each',\n",
       " 'seemed',\n",
       " 'found',\n",
       " 'from',\n",
       " 'was',\n",
       " 'we',\n",
       " 'top',\n",
       " 'hereby',\n",
       " 'as',\n",
       " 'almost',\n",
       " 'until',\n",
       " 'upon',\n",
       " 'former',\n",
       " 'behind',\n",
       " 'nine',\n",
       " 'somehow',\n",
       " 'thru',\n",
       " 'when',\n",
       " 'becoming',\n",
       " 'else',\n",
       " 'seems',\n",
       " 'nevertheless',\n",
       " 'besides',\n",
       " 'and',\n",
       " 'therein',\n",
       " 'also',\n",
       " 'neither',\n",
       " 'becomes',\n",
       " 'than',\n",
       " 'back',\n",
       " 'amoungst',\n",
       " 'hence',\n",
       " 'anywhere',\n",
       " 'whither',\n",
       " 'hereupon',\n",
       " 'last',\n",
       " 'now',\n",
       " 'sometime',\n",
       " 'further',\n",
       " 'once',\n",
       " 'at',\n",
       " 'whereupon',\n",
       " 'some',\n",
       " 'she',\n",
       " 'two',\n",
       " 'mill',\n",
       " 'could',\n",
       " 'throughout',\n",
       " 'those',\n",
       " 'whole',\n",
       " 'whereas',\n",
       " 'will',\n",
       " 'name',\n",
       " 'hundred',\n",
       " 'beforehand',\n",
       " 'thin',\n",
       " 'twelve',\n",
       " 'fifteen',\n",
       " 'within',\n",
       " 'that',\n",
       " 'you',\n",
       " 'own',\n",
       " 'take',\n",
       " 'however',\n",
       " 'next',\n",
       " 'find',\n",
       " 'often',\n",
       " 'made',\n",
       " 'empty',\n",
       " 'sometimes',\n",
       " 'moreover',\n",
       " 'the',\n",
       " 'these',\n",
       " 'alone',\n",
       " 'by',\n",
       " 'eleven',\n",
       " 'something',\n",
       " 'together',\n",
       " 'keep',\n",
       " 'were',\n",
       " 'nothing',\n",
       " 'after',\n",
       " 'has',\n",
       " 'detail',\n",
       " 'though',\n",
       " 'seem',\n",
       " 'their',\n",
       " 'yourselves',\n",
       " 'another',\n",
       " 'among',\n",
       " 'so',\n",
       " 'well',\n",
       " 'yourself',\n",
       " 'a',\n",
       " 'across',\n",
       " 'always',\n",
       " 'thereby',\n",
       " 'under',\n",
       " 'themselves',\n",
       " 'anything',\n",
       " 'all',\n",
       " 'third',\n",
       " 'toward',\n",
       " 'system',\n",
       " 'whom',\n",
       " 'down',\n",
       " 'meanwhile',\n",
       " 'cry',\n",
       " 'same',\n",
       " 'what',\n",
       " 'namely',\n",
       " 'but',\n",
       " 'around',\n",
       " 'call',\n",
       " 'only',\n",
       " 'afterwards',\n",
       " 'fantasy',\n",
       " 'scifi',\n",
       " 'sci',\n",
       " 'fi',\n",
       " 'like',\n",
       " 'just',\n",
       " 'good',\n",
       " 'really',\n",
       " 'think',\n",
       " 'don',\n",
       " 'time',\n",
       " 'people',\n",
       " 'com',\n",
       " 'series',\n",
       " 'https',\n",
       " 'gt',\n",
       " 'book',\n",
       " 've',\n",
       " 'great',\n",
       " 'story',\n",
       " 'www',\n",
       " 'read',\n",
       " 'way',\n",
       " 'know',\n",
       " 'books',\n",
       " 'character',\n",
       " 'got',\n",
       " 'lot',\n",
       " 'didn',\n",
       " 'make',\n",
       " 'going',\n",
       " 'pretty',\n",
       " 'love',\n",
       " 'say',\n",
       " 'actually',\n",
       " 'reddit',\n",
       " 'll',\n",
       " 'things',\n",
       " 'did',\n",
       " 'better',\n",
       " 'years',\n",
       " 'world',\n",
       " 'thing',\n",
       " 'want',\n",
       " 'characters',\n",
       " 'sure',\n",
       " 'new',\n",
       " 'right',\n",
       " 'doesn',\n",
       " 'best',\n",
       " 'end',\n",
       " 'point',\n",
       " 'does',\n",
       " 'different',\n",
       " 'maybe']"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stops_df = pd.read_csv('./data/stopwords.csv')\n",
    "stops = list(stops_df['0'])\n",
    "stops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>types</th>\n",
       "      <th>Simple NB</th>\n",
       "      <th>Simple LR</th>\n",
       "      <th>LR 5000 features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fantasy</td>\n",
       "      <td>fantasy</td>\n",
       "      <td>fantasy</td>\n",
       "      <td>fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fantasy</td>\n",
       "      <td>fantasy</td>\n",
       "      <td>fantasy</td>\n",
       "      <td>fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>scifi</td>\n",
       "      <td>scifi</td>\n",
       "      <td>scifi</td>\n",
       "      <td>scifi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>scifi</td>\n",
       "      <td>scifi</td>\n",
       "      <td>scifi</td>\n",
       "      <td>scifi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>scifi</td>\n",
       "      <td>scifi</td>\n",
       "      <td>scifi</td>\n",
       "      <td>scifi</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     types Simple NB Simple LR LR 5000 features\n",
       "0  fantasy   fantasy   fantasy          fantasy\n",
       "1  fantasy   fantasy   fantasy          fantasy\n",
       "2    scifi     scifi     scifi            scifi\n",
       "3    scifi     scifi     scifi            scifi\n",
       "4    scifi     scifi     scifi            scifi"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = pd.read_csv('./data/predictions.csv')\n",
    "predictions.drop(columns = 'Unnamed: 0', inplace=True)\n",
    "predictions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>types</th>\n",
       "      <th>prediction</th>\n",
       "      <th>err type</th>\n",
       "      <th>err label</th>\n",
       "      <th>probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>fantasy, correct</td>\n",
       "      <td>2.081928e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>fantasy, correct</td>\n",
       "      <td>2.242084e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>scifi, correct</td>\n",
       "      <td>9.309696e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>scifi, correct</td>\n",
       "      <td>9.962833e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>scifi, correct</td>\n",
       "      <td>7.649797e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   types  prediction  err type         err label   probability\n",
       "0      0           0         0  fantasy, correct  2.081928e-01\n",
       "1      0           0         0  fantasy, correct  2.242084e-08\n",
       "2      1           1         3    scifi, correct  9.309696e-01\n",
       "3      1           1         3    scifi, correct  9.962833e-01\n",
       "4      1           1         3    scifi, correct  7.649797e-01"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_probabilities = pd.read_csv('./data/predicted_probabilities.csv')\n",
    "predicted_probabilities.drop(columns = 'Unnamed: 0', inplace=True)\n",
    "predicted_probabilities.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>train</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Baseline</td>\n",
       "      <td>0.501809</td>\n",
       "      <td>0.501909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NBayesian</td>\n",
       "      <td>0.829448</td>\n",
       "      <td>0.779184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LogReg</td>\n",
       "      <td>0.940715</td>\n",
       "      <td>0.814949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LogReg 5000</td>\n",
       "      <td>0.894628</td>\n",
       "      <td>0.801085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LR with Lasso, a=1</td>\n",
       "      <td>0.892867</td>\n",
       "      <td>0.789237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LR with Lasso, a=10</td>\n",
       "      <td>0.977844</td>\n",
       "      <td>0.796527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LR with Ridge a=1 (ran 0.1, 1, 10)</td>\n",
       "      <td>0.951472</td>\n",
       "      <td>0.806389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>knn, k=1,   uniform</td>\n",
       "      <td>0.993139</td>\n",
       "      <td>0.610206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>knn, k=3,   uniform</td>\n",
       "      <td>0.766795</td>\n",
       "      <td>0.607847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>knn, k=5,   uniform</td>\n",
       "      <td>0.761221</td>\n",
       "      <td>0.618997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>knn, k=25,  uniform</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.591981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>knn, k=501, uniform</td>\n",
       "      <td>0.508219</td>\n",
       "      <td>0.509863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>knn, k=1,   distance</td>\n",
       "      <td>0.993139</td>\n",
       "      <td>0.610206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>knn, k=3,   distance</td>\n",
       "      <td>0.993353</td>\n",
       "      <td>0.610635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>knn, k=5,   distance</td>\n",
       "      <td>0.993425</td>\n",
       "      <td>0.620497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>knn, k=25,  distance</td>\n",
       "      <td>0.993425</td>\n",
       "      <td>0.595197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>knn, k=501, distance</td>\n",
       "      <td>0.993425</td>\n",
       "      <td>0.520154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Tfid + LR</td>\n",
       "      <td>0.918239</td>\n",
       "      <td>0.809177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Tfid + LR + LASSO</td>\n",
       "      <td>0.831189</td>\n",
       "      <td>0.782804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Tfid + LR + Ridge</td>\n",
       "      <td>0.918239</td>\n",
       "      <td>0.809177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Stem + Tfid + LR</td>\n",
       "      <td>0.902158</td>\n",
       "      <td>0.811535</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 model     train      test\n",
       "0                             Baseline  0.501809  0.501909\n",
       "1                            NBayesian  0.829448  0.779184\n",
       "2                               LogReg  0.940715  0.814949\n",
       "3                          LogReg 5000  0.894628  0.801085\n",
       "4                   LR with Lasso, a=1  0.892867  0.789237\n",
       "5                  LR with Lasso, a=10  0.977844  0.796527\n",
       "6   LR with Ridge a=1 (ran 0.1, 1, 10)  0.951472  0.806389\n",
       "7                  knn, k=1,   uniform  0.993139  0.610206\n",
       "8                  knn, k=3,   uniform  0.766795  0.607847\n",
       "9                  knn, k=5,   uniform  0.761221  0.618997\n",
       "10                 knn, k=25,  uniform  0.666667  0.591981\n",
       "11                 knn, k=501, uniform  0.508219  0.509863\n",
       "12                knn, k=1,   distance  0.993139  0.610206\n",
       "13                knn, k=3,   distance  0.993353  0.610635\n",
       "14                knn, k=5,   distance  0.993425  0.620497\n",
       "15                knn, k=25,  distance  0.993425  0.595197\n",
       "16                knn, k=501, distance  0.993425  0.520154\n",
       "17                           Tfid + LR  0.918239  0.809177\n",
       "18                   Tfid + LR + LASSO  0.831189  0.782804\n",
       "19                   Tfid + LR + Ridge  0.918239  0.809177\n",
       "20                    Stem + Tfid + LR  0.902158  0.811535"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = pd.read_csv('./data/scores.csv')\n",
    "scores.drop(columns='ndx',inplace=True)\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make X & y, train test split, and vectorize using CountVectorizer (since it was a bit better than TfidVectorizer) - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['comment']\n",
    "y = df['types']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,random_state = 42, stratify=y)\n",
    "cv = CountVectorizer(stop_words=stops)\n",
    "cv.fit(X_train,y_train)\n",
    "Xcvec_train = tv.transform(X_train)\n",
    "Xcvec_test  = tv.transform(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do a simple Random Forest, default params:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 0.9931389365351629, Test: 0.7765866209262435\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier()\n",
    "rf.fit(Xcvec_train,y_train)\n",
    "rf_train = rf.score(Xcvec_train,y_train)\n",
    "rf_test  = rf.score(Xcvec_test,y_test)\n",
    "print(f'Train: {rf_train}, Test: {rf_test}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pretty impressively overfit on train, still not beating log reg for test.\n",
    "\n",
    "Now for some tuning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'max_depth': [10, 100, 1000],\n",
    "    'min_samples_split': [10, 100, 1000]\n",
    "}\n",
    "\n",
    "# define grid search\n",
    "rf = RandomForestClassifier()\n",
    "gs = GridSearchCV(rf, param_grid=param_grid, cv=5, verbose = 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "[CV] max_depth=10, min_samples_split=10 ..............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............... max_depth=10, min_samples_split=10, total=   2.6s\n",
      "[CV] max_depth=10, min_samples_split=10 ..............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.6s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............... max_depth=10, min_samples_split=10, total=   2.1s\n",
      "[CV] max_depth=10, min_samples_split=10 ..............................\n",
      "[CV] ............... max_depth=10, min_samples_split=10, total=   2.1s\n",
      "[CV] max_depth=10, min_samples_split=10 ..............................\n",
      "[CV] ............... max_depth=10, min_samples_split=10, total=   2.2s\n",
      "[CV] max_depth=10, min_samples_split=10 ..............................\n",
      "[CV] ............... max_depth=10, min_samples_split=10, total=   2.2s\n",
      "[CV] max_depth=10, min_samples_split=100 .............................\n",
      "[CV] .............. max_depth=10, min_samples_split=100, total=   2.1s\n",
      "[CV] max_depth=10, min_samples_split=100 .............................\n",
      "[CV] .............. max_depth=10, min_samples_split=100, total=   2.1s\n",
      "[CV] max_depth=10, min_samples_split=100 .............................\n",
      "[CV] .............. max_depth=10, min_samples_split=100, total=   2.6s\n",
      "[CV] max_depth=10, min_samples_split=100 .............................\n",
      "[CV] .............. max_depth=10, min_samples_split=100, total=   2.0s\n",
      "[CV] max_depth=10, min_samples_split=100 .............................\n",
      "[CV] .............. max_depth=10, min_samples_split=100, total=   2.4s\n",
      "[CV] max_depth=10, min_samples_split=1000 ............................\n",
      "[CV] ............. max_depth=10, min_samples_split=1000, total=   2.2s\n",
      "[CV] max_depth=10, min_samples_split=1000 ............................\n",
      "[CV] ............. max_depth=10, min_samples_split=1000, total=   2.1s\n",
      "[CV] max_depth=10, min_samples_split=1000 ............................\n",
      "[CV] ............. max_depth=10, min_samples_split=1000, total=   2.1s\n",
      "[CV] max_depth=10, min_samples_split=1000 ............................\n",
      "[CV] ............. max_depth=10, min_samples_split=1000, total=   2.1s\n",
      "[CV] max_depth=10, min_samples_split=1000 ............................\n",
      "[CV] ............. max_depth=10, min_samples_split=1000, total=   2.5s\n",
      "[CV] max_depth=100, min_samples_split=10 .............................\n",
      "[CV] .............. max_depth=100, min_samples_split=10, total=  20.6s\n",
      "[CV] max_depth=100, min_samples_split=10 .............................\n",
      "[CV] .............. max_depth=100, min_samples_split=10, total=  18.9s\n",
      "[CV] max_depth=100, min_samples_split=10 .............................\n",
      "[CV] .............. max_depth=100, min_samples_split=10, total=  24.3s\n",
      "[CV] max_depth=100, min_samples_split=10 .............................\n",
      "[CV] .............. max_depth=100, min_samples_split=10, total=  24.0s\n",
      "[CV] max_depth=100, min_samples_split=10 .............................\n",
      "[CV] .............. max_depth=100, min_samples_split=10, total=  21.2s\n",
      "[CV] max_depth=100, min_samples_split=100 ............................\n",
      "[CV] ............. max_depth=100, min_samples_split=100, total=  15.9s\n",
      "[CV] max_depth=100, min_samples_split=100 ............................\n",
      "[CV] ............. max_depth=100, min_samples_split=100, total=  14.3s\n",
      "[CV] max_depth=100, min_samples_split=100 ............................\n",
      "[CV] ............. max_depth=100, min_samples_split=100, total=  11.7s\n",
      "[CV] max_depth=100, min_samples_split=100 ............................\n",
      "[CV] ............. max_depth=100, min_samples_split=100, total=  12.1s\n",
      "[CV] max_depth=100, min_samples_split=100 ............................\n",
      "[CV] ............. max_depth=100, min_samples_split=100, total=  12.8s\n",
      "[CV] max_depth=100, min_samples_split=1000 ...........................\n",
      "[CV] ............ max_depth=100, min_samples_split=1000, total=  11.6s\n",
      "[CV] max_depth=100, min_samples_split=1000 ...........................\n",
      "[CV] ............ max_depth=100, min_samples_split=1000, total=  11.8s\n",
      "[CV] max_depth=100, min_samples_split=1000 ...........................\n",
      "[CV] ............ max_depth=100, min_samples_split=1000, total=  14.2s\n",
      "[CV] max_depth=100, min_samples_split=1000 ...........................\n",
      "[CV] ............ max_depth=100, min_samples_split=1000, total=  12.5s\n",
      "[CV] max_depth=100, min_samples_split=1000 ...........................\n",
      "[CV] ............ max_depth=100, min_samples_split=1000, total=  12.1s\n",
      "[CV] max_depth=1000, min_samples_split=10 ............................\n",
      "[CV] ............. max_depth=1000, min_samples_split=10, total=  35.4s\n",
      "[CV] max_depth=1000, min_samples_split=10 ............................\n",
      "[CV] ............. max_depth=1000, min_samples_split=10, total=  35.6s\n",
      "[CV] max_depth=1000, min_samples_split=10 ............................\n",
      "[CV] ............. max_depth=1000, min_samples_split=10, total=  38.3s\n",
      "[CV] max_depth=1000, min_samples_split=10 ............................\n",
      "[CV] ............. max_depth=1000, min_samples_split=10, total=  36.6s\n",
      "[CV] max_depth=1000, min_samples_split=10 ............................\n",
      "[CV] ............. max_depth=1000, min_samples_split=10, total=  40.8s\n",
      "[CV] max_depth=1000, min_samples_split=100 ...........................\n",
      "[CV] ............ max_depth=1000, min_samples_split=100, total=  31.3s\n",
      "[CV] max_depth=1000, min_samples_split=100 ...........................\n",
      "[CV] ............ max_depth=1000, min_samples_split=100, total=  32.3s\n",
      "[CV] max_depth=1000, min_samples_split=100 ...........................\n",
      "[CV] ............ max_depth=1000, min_samples_split=100, total=  30.0s\n",
      "[CV] max_depth=1000, min_samples_split=100 ...........................\n",
      "[CV] ............ max_depth=1000, min_samples_split=100, total=  30.2s\n",
      "[CV] max_depth=1000, min_samples_split=100 ...........................\n",
      "[CV] ............ max_depth=1000, min_samples_split=100, total=  31.5s\n",
      "[CV] max_depth=1000, min_samples_split=1000 ..........................\n",
      "[CV] ........... max_depth=1000, min_samples_split=1000, total=  30.0s\n",
      "[CV] max_depth=1000, min_samples_split=1000 ..........................\n",
      "[CV] ........... max_depth=1000, min_samples_split=1000, total=  44.9s\n",
      "[CV] max_depth=1000, min_samples_split=1000 ..........................\n",
      "[CV] ........... max_depth=1000, min_samples_split=1000, total=  33.0s\n",
      "[CV] max_depth=1000, min_samples_split=1000 ..........................\n",
      "[CV] ........... max_depth=1000, min_samples_split=1000, total=  40.4s\n",
      "[CV] max_depth=1000, min_samples_split=1000 ..........................\n",
      "[CV] ........... max_depth=1000, min_samples_split=1000, total=  39.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  45 out of  45 | elapsed: 13.4min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=RandomForestClassifier(),\n",
       "             param_grid={'max_depth': [10, 100, 1000],\n",
       "                         'min_samples_split': [10, 100, 1000]},\n",
       "             verbose=2)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.fit(Xcvec_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 1000, 'min_samples_split': 10}"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.776086093241204"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_score_\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score on training set: 0.98363350485992\n",
      "Score on testing set: 0.7761578044596913\n"
     ]
    }
   ],
   "source": [
    "print(f'Score on training set: {gs.score(Xcvec_train,y_train)}')\n",
    "print(f'Score on testing set: {gs.score(Xcvec_test,y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "subreddits = ['fantasy', 'scifi']\n",
    "fig = plt.figure(figsize=(12,5));\n",
    "ax = fig.add_subplot(121);\n",
    "preds_rf = gs.predict(Xcvec_test)\n",
    "cm = confusion_matrix(y_test, preds_rf)\n",
    "cm = cm*100/sum(sum(cm));\n",
    "sns.heatmap(cm,ax=ax,annot=True, vmin = 0, vmax = 50, cmap='coolwarm');\n",
    "ax.set_xticklabels(subreddits);\n",
    "ax.set_yticklabels(subreddits);\n",
    "plt.xlabel('Predicted');\n",
    "plt.ylabel('Actual');\n",
    "plt.title('Best Random Forest Model');\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Still not an improvement. Plus, Random Forests don't have the interpretability of log reg, and I need that to answer my problem statement. But I did just want to see if I could get it really accurate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Support Vector model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'accuracy_score' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-64c9110cae04>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Evaluate model.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0msvc_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msvc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXcvev_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0msvc_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msvc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXcvev_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'accuracy_score' is not defined"
     ]
    }
   ],
   "source": [
    "svc = SVC(\n",
    "    C = 1000,\n",
    "    kernel = 'rbf', \n",
    "    gamma = 'scale'\n",
    ")\n",
    "\n",
    "# Fit on training data.\n",
    "svc.fit(Xcvec_train, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 0.9933533447684391, Test: 0.8096054888507719\n"
     ]
    }
   ],
   "source": [
    "# Evaluate model.\n",
    "svc_train = accuracy_score(y_train, svc.predict(Xcvec_train))\n",
    "svc_test = accuracy_score(y_test, svc.predict(Xcvec_test))\n",
    "print(f'Train: {svc_train}, Test: {svc_test}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Almost as good as the log reg, but another massively overfit model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes on Decision Trees vs. Random Forests:\n",
    "\n",
    "A decision tree is built on an entire dataset, using all the features/variables of interest, whereas a random forest randomly selects observations/rows and specific features/variables to build multiple decision trees from and then averages the results.\n",
    "\n",
    "https://www.google.com/search?client=safari&rls=en&q=difference+between+decision+tree+and+random+forest&ie=UTF-8&oe=UTF-8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Last notebook left:\n",
    "\n",
    "* project3_7: Enough modeling, time to visualize.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
